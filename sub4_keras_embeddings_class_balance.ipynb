{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bhaskar Boora\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import gensim\n",
    "from tqdm import tqdm\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Dense, CuDNNLSTM, Embedding, Bidirectional\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, Callback\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hmid</th>\n",
       "      <th>reflection_period</th>\n",
       "      <th>cleaned_hm</th>\n",
       "      <th>num_sentence</th>\n",
       "      <th>predicted_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27673</td>\n",
       "      <td>24h</td>\n",
       "      <td>i went on a successful date with someone i fel...</td>\n",
       "      <td>1</td>\n",
       "      <td>affection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27674</td>\n",
       "      <td>24h</td>\n",
       "      <td>i was happy when my son got 90% marks in his e...</td>\n",
       "      <td>1</td>\n",
       "      <td>affection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27675</td>\n",
       "      <td>24h</td>\n",
       "      <td>i went to the gym this morning and did yoga.</td>\n",
       "      <td>1</td>\n",
       "      <td>exercise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27676</td>\n",
       "      <td>24h</td>\n",
       "      <td>we had a serious talk with some friends of our...</td>\n",
       "      <td>2</td>\n",
       "      <td>bonding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27677</td>\n",
       "      <td>24h</td>\n",
       "      <td>i went with grandchildren to butterfly display...</td>\n",
       "      <td>1</td>\n",
       "      <td>affection</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hmid reflection_period                                         cleaned_hm  \\\n",
       "0  27673               24h  i went on a successful date with someone i fel...   \n",
       "1  27674               24h  i was happy when my son got 90% marks in his e...   \n",
       "2  27675               24h       i went to the gym this morning and did yoga.   \n",
       "3  27676               24h  we had a serious talk with some friends of our...   \n",
       "4  27677               24h  i went with grandchildren to butterfly display...   \n",
       "\n",
       "   num_sentence predicted_category  \n",
       "0             1          affection  \n",
       "1             1          affection  \n",
       "2             1           exercise  \n",
       "3             2            bonding  \n",
       "4             1          affection  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('D:/Datasets/mc-sent-2/dataset/hm_train.csv', low_memory=False)\n",
    "df.cleaned_hm = df.cleaned_hm.apply(str.lower)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df.predicted_category\n",
    "df.drop(['reflection_period', 'num_sentence', 'predicted_category'], axis=1, inplace=True)\n",
    "classes = sorted(labels.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['achievement',\n",
       " 'affection',\n",
       " 'bonding',\n",
       " 'enjoy_the_moment',\n",
       " 'exercise',\n",
       " 'leisure',\n",
       " 'nature']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val, y_train, y_val = train_test_split(df, labels, test_size=0.15, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df_train.cleaned_hm)\n",
    "num_words = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51272"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_train_set = tokenizer.texts_to_sequences(df_train.cleaned_hm)\n",
    "len(encoded_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bhaskar Boora\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\Bhaskar Boora\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\pandas\\core\\frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hmid</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45032</th>\n",
       "      <td>72952</td>\n",
       "      <td>[6, 113, 13, 24, 15, 24, 13, 1, 77, 8, 33, 9019]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48648</th>\n",
       "      <td>76580</td>\n",
       "      <td>[72, 831, 6, 262, 1, 147, 494, 37, 95]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30240</th>\n",
       "      <td>58081</td>\n",
       "      <td>[2, 2408, 3196, 556, 30, 42, 178, 77, 16, 2135...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30184</th>\n",
       "      <td>58025</td>\n",
       "      <td>[1, 356, 8, 32, 715, 161, 929, 53, 4, 7, 47, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54765</th>\n",
       "      <td>82717</td>\n",
       "      <td>[1, 35, 310, 1307, 609, 30, 551, 8, 2, 327, 406]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        hmid                                             tokens\n",
       "45032  72952   [6, 113, 13, 24, 15, 24, 13, 1, 77, 8, 33, 9019]\n",
       "48648  76580             [72, 831, 6, 262, 1, 147, 494, 37, 95]\n",
       "30240  58081  [2, 2408, 3196, 556, 30, 42, 178, 77, 16, 2135...\n",
       "30184  58025  [1, 356, 8, 32, 715, 161, 929, 53, 4, 7, 47, 5...\n",
       "54765  82717   [1, 35, 310, 1307, 609, 30, 551, 8, 2, 327, 406]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['tokens'] = encoded_train_set\n",
    "df_train.drop(['cleaned_hm'], axis=1, inplace=True)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45032    enjoy_the_moment\n",
       "48648         achievement\n",
       "30240           affection\n",
       "30184           affection\n",
       "54765         achievement\n",
       "Name: predicted_category, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bhaskar Boora\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hmid</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45032</th>\n",
       "      <td>72952</td>\n",
       "      <td>[6, 113, 13, 24, 15, 24, 13, 1, 77, 8, 33, 901...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48648</th>\n",
       "      <td>76580</td>\n",
       "      <td>[72, 831, 6, 262, 1, 147, 494, 37, 95, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30240</th>\n",
       "      <td>58081</td>\n",
       "      <td>[2, 2408, 3196, 556, 30, 42, 178, 77, 16, 2135...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30184</th>\n",
       "      <td>58025</td>\n",
       "      <td>[1, 356, 8, 32, 715, 161, 929, 53, 4, 7, 47, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54765</th>\n",
       "      <td>82717</td>\n",
       "      <td>[1, 35, 310, 1307, 609, 30, 551, 8, 2, 327, 40...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        hmid                                             tokens\n",
       "45032  72952  [6, 113, 13, 24, 15, 24, 13, 1, 77, 8, 33, 901...\n",
       "48648  76580  [72, 831, 6, 262, 1, 147, 494, 37, 95, 0, 0, 0...\n",
       "30240  58081  [2, 2408, 3196, 556, 30, 42, 178, 77, 16, 2135...\n",
       "30184  58025  [1, 356, 8, 32, 715, 161, 929, 53, 4, 7, 47, 5...\n",
       "54765  82717  [1, 35, 310, 1307, 609, 30, 551, 8, 2, 327, 40..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = 100\n",
    "padded = pad_sequences(encoded_train_set, maxlen=max_len, padding='post')\n",
    "trainset = [list(doc) for doc in padded]\n",
    "df_train['tokens'] = trainset\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bhaskar Boora\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\Bhaskar Boora\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hmid</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19748</th>\n",
       "      <td>47530</td>\n",
       "      <td>[1, 65, 3, 163, 1091, 360, 16, 409, 53, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26811</th>\n",
       "      <td>54629</td>\n",
       "      <td>[1, 17, 5, 701, 2634, 6, 2105, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52605</th>\n",
       "      <td>80546</td>\n",
       "      <td>[1, 91, 2, 129, 3, 27, 3938, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7848</th>\n",
       "      <td>35577</td>\n",
       "      <td>[523, 41, 59, 19, 2873, 13, 1, 19, 75, 84, 41,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3435</th>\n",
       "      <td>31130</td>\n",
       "      <td>[2, 231, 7, 619, 8, 6, 327, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        hmid                                             tokens\n",
       "19748  47530  [1, 65, 3, 163, 1091, 360, 16, 409, 53, 0, 0, ...\n",
       "26811  54629  [1, 17, 5, 701, 2634, 6, 2105, 0, 0, 0, 0, 0, ...\n",
       "52605  80546  [1, 91, 2, 129, 3, 27, 3938, 0, 0, 0, 0, 0, 0,...\n",
       "7848   35577  [523, 41, 59, 19, 2873, 13, 1, 19, 75, 84, 41,...\n",
       "3435   31130  [2, 231, 7, 619, 8, 6, 327, 0, 0, 0, 0, 0, 0, ..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_val_set = tokenizer.texts_to_sequences(df_val.cleaned_hm)\n",
    "print(len(encoded_val_set))\n",
    "\n",
    "df_val['tokens'] = encoded_val_set\n",
    "df_val.drop(['cleaned_hm'], axis=1, inplace=True)\n",
    "padded_val = pad_sequences(encoded_val_set, maxlen=max_len, padding='post')\n",
    "valset = [list(doc) for doc in padded_val]\n",
    "df_val['tokens'] = valset;\n",
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(max_len,), dtype='int32')\n",
    "embedding = Embedding(num_words, 200, input_length=max_len, trainable=True)(inputs)\n",
    "x = CuDNNLSTM(256, return_sequences=True)(embedding)\n",
    "x = CuDNNLSTM(64)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "outputs = Dense(7, activation='softmax')(x)\n",
    "model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51272, 100) (9049, 100)\n",
      "(51272, 7) (9049, 7)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array([np.array(x) for x in df_train.tokens])\n",
    "x_val = np.array([np.array(x) for x in df_val.tokens])\n",
    "print(x_train.shape, x_val.shape)\n",
    "\n",
    "label_to_ohv = dict()\n",
    "for i, cls in enumerate(classes):\n",
    "    ohv = np.zeros((7), dtype='int8')\n",
    "    ohv[i] = 1\n",
    "    label_to_ohv[cls] = tuple(ohv)\n",
    "    \n",
    "ohv_to_label = dict()\n",
    "for k, v in label_to_ohv.items():\n",
    "    ohv_to_label[v] = k\n",
    "\n",
    "y_train = np.array([np.array(label_to_ohv[label]) for label in y_train])\n",
    "y_val = np.array([np.array(label_to_ohv[label]) for label in y_val])\n",
    "print(y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anything less than $10^{-4}$ seems to be a good learning rate to use. Going lower would require more epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accounting for class imbalance for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.42504122,  0.41270525,  1.31341041,  1.32410659, 11.82069371,\n",
       "        2.03142049,  7.64621625])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(sorted(labels)), labels)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes are observed to be extremely skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 100, 200)          3980800   \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (None, 100, 256)          468992    \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_2 (CuDNNLSTM)     (None, 64)                82432     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 4,536,839\n",
      "Trainable params: 4,536,839\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 51272 samples, validate on 9049 samples\n",
      "Epoch 1/20\n",
      " - 40s - loss: 1.5369 - categorical_accuracy: 0.3426 - val_loss: 1.5295 - val_categorical_accuracy: 0.3424\n",
      "\n",
      "Epoch 00001: val_categorical_accuracy improved from -inf to 0.34236, saving model to D:/Datasets/mc-sent-2/embedding_v4.h5\n",
      "Epoch 2/20\n",
      " - 36s - loss: 1.5159 - categorical_accuracy: 0.3618 - val_loss: 1.2107 - val_categorical_accuracy: 0.6039\n",
      "\n",
      "Epoch 00002: val_categorical_accuracy improved from 0.34236 to 0.60393, saving model to D:/Datasets/mc-sent-2/embedding_v4.h5\n",
      "Epoch 3/20\n",
      " - 36s - loss: 0.8585 - categorical_accuracy: 0.6945 - val_loss: 0.5687 - val_categorical_accuracy: 0.8184\n",
      "\n",
      "Epoch 00003: val_categorical_accuracy improved from 0.60393 to 0.81843, saving model to D:/Datasets/mc-sent-2/embedding_v4.h5\n",
      "Epoch 4/20\n",
      " - 36s - loss: 0.3837 - categorical_accuracy: 0.8774 - val_loss: 0.3700 - val_categorical_accuracy: 0.8771\n",
      "\n",
      "Epoch 00004: val_categorical_accuracy improved from 0.81843 to 0.87711, saving model to D:/Datasets/mc-sent-2/embedding_v4.h5\n",
      "Epoch 5/20\n",
      " - 36s - loss: 0.2293 - categorical_accuracy: 0.9256 - val_loss: 0.3516 - val_categorical_accuracy: 0.8936\n",
      "\n",
      "Epoch 00005: val_categorical_accuracy improved from 0.87711 to 0.89358, saving model to D:/Datasets/mc-sent-2/embedding_v4.h5\n",
      "Epoch 6/20\n",
      " - 36s - loss: 0.1476 - categorical_accuracy: 0.9533 - val_loss: 0.3389 - val_categorical_accuracy: 0.8986\n",
      "\n",
      "Epoch 00006: val_categorical_accuracy improved from 0.89358 to 0.89855, saving model to D:/Datasets/mc-sent-2/embedding_v4.h5\n",
      "Epoch 7/20\n",
      " - 36s - loss: 0.1060 - categorical_accuracy: 0.9669 - val_loss: 0.4158 - val_categorical_accuracy: 0.8791\n",
      "\n",
      "Epoch 00007: val_categorical_accuracy did not improve from 0.89855\n",
      "Epoch 8/20\n",
      " - 36s - loss: 0.0830 - categorical_accuracy: 0.9735 - val_loss: 0.3998 - val_categorical_accuracy: 0.8981\n",
      "\n",
      "Epoch 00008: val_categorical_accuracy did not improve from 0.89855\n",
      "Epoch 9/20\n",
      " - 36s - loss: 0.0654 - categorical_accuracy: 0.9798 - val_loss: 0.4075 - val_categorical_accuracy: 0.9008\n",
      "\n",
      "Epoch 00009: val_categorical_accuracy improved from 0.89855 to 0.90076, saving model to D:/Datasets/mc-sent-2/embedding_v4.h5\n",
      "Epoch 10/20\n",
      " - 36s - loss: 0.0539 - categorical_accuracy: 0.9834 - val_loss: 0.4127 - val_categorical_accuracy: 0.9011\n",
      "\n",
      "Epoch 00010: val_categorical_accuracy improved from 0.90076 to 0.90109, saving model to D:/Datasets/mc-sent-2/embedding_v4.h5\n",
      "Epoch 11/20\n",
      " - 36s - loss: 0.0427 - categorical_accuracy: 0.9867 - val_loss: 0.4381 - val_categorical_accuracy: 0.8935\n",
      "\n",
      "Epoch 00011: val_categorical_accuracy did not improve from 0.90109\n",
      "Epoch 12/20\n",
      " - 36s - loss: 0.0394 - categorical_accuracy: 0.9877 - val_loss: 0.4461 - val_categorical_accuracy: 0.8963\n",
      "\n",
      "Epoch 00012: val_categorical_accuracy did not improve from 0.90109\n",
      "Epoch 13/20\n",
      " - 36s - loss: 0.0314 - categorical_accuracy: 0.9905 - val_loss: 0.4771 - val_categorical_accuracy: 0.8950\n",
      "\n",
      "Epoch 00013: val_categorical_accuracy did not improve from 0.90109\n",
      "Epoch 14/20\n",
      " - 36s - loss: 0.0293 - categorical_accuracy: 0.9909 - val_loss: 0.4665 - val_categorical_accuracy: 0.9014\n",
      "\n",
      "Epoch 00014: val_categorical_accuracy improved from 0.90109 to 0.90143, saving model to D:/Datasets/mc-sent-2/embedding_v4.h5\n",
      "Epoch 15/20\n",
      " - 36s - loss: 0.0253 - categorical_accuracy: 0.9918 - val_loss: 0.4958 - val_categorical_accuracy: 0.8990\n",
      "\n",
      "Epoch 00015: val_categorical_accuracy did not improve from 0.90143\n",
      "Epoch 16/20\n",
      " - 36s - loss: 0.0202 - categorical_accuracy: 0.9933 - val_loss: 0.5199 - val_categorical_accuracy: 0.9015\n",
      "\n",
      "Epoch 00016: val_categorical_accuracy improved from 0.90143 to 0.90154, saving model to D:/Datasets/mc-sent-2/embedding_v4.h5\n",
      "Epoch 17/20\n",
      " - 36s - loss: 0.0188 - categorical_accuracy: 0.9939 - val_loss: 0.5346 - val_categorical_accuracy: 0.8989\n",
      "\n",
      "Epoch 00017: val_categorical_accuracy did not improve from 0.90154\n",
      "Epoch 18/20\n",
      " - 37s - loss: 0.0185 - categorical_accuracy: 0.9942 - val_loss: 0.5660 - val_categorical_accuracy: 0.8946\n",
      "\n",
      "Epoch 00018: val_categorical_accuracy did not improve from 0.90154\n",
      "Epoch 19/20\n",
      " - 33s - loss: 0.0145 - categorical_accuracy: 0.9951 - val_loss: 0.6097 - val_categorical_accuracy: 0.8962\n",
      "\n",
      "Epoch 00019: val_categorical_accuracy did not improve from 0.90154\n",
      "Epoch 20/20\n",
      " - 34s - loss: 0.0147 - categorical_accuracy: 0.9953 - val_loss: 0.6233 - val_categorical_accuracy: 0.8925\n",
      "\n",
      "Epoch 00020: val_categorical_accuracy did not improve from 0.90154\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24f22d347b8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint('D:/Datasets/mc-sent-2/embedding_v4.h5', save_best_only=True, monitor='val_categorical_accuracy', mode='max', verbose=1)\n",
    "model.compile(optimizer=Adam(lr=4e-4, decay=1e-6), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model.summary()\n",
    "model.fit(x_train, y_train,\n",
    "          validation_data=(x_val, y_val),\n",
    "          callbacks=[checkpoint],\n",
    "          class_weight=class_weights,\n",
    "          epochs=20,\n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('D:/Datasets/mc-sent-2/embedding_v4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hmid</th>\n",
       "      <th>cleaned_hm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88305</td>\n",
       "      <td>i spent the weekend in chicago with my friends.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88306</td>\n",
       "      <td>we moved back into our house after a remodel. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88307</td>\n",
       "      <td>my fiance proposed to me in front of my family...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88308</td>\n",
       "      <td>i ate lobster at a fancy restaurant with some ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88309</td>\n",
       "      <td>i went out to a nice restaurant on a date with...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hmid                                         cleaned_hm\n",
       "0  88305    i spent the weekend in chicago with my friends.\n",
       "1  88306  we moved back into our house after a remodel. ...\n",
       "2  88307  my fiance proposed to me in front of my family...\n",
       "3  88308  i ate lobster at a fancy restaurant with some ...\n",
       "4  88309  i went out to a nice restaurant on a date with..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('D:/Datasets/mc-sent-2/dataset/hm_test.csv', low_memory=False)\n",
    "df_test.drop(['reflection_period', 'num_sentence'], axis=1, inplace=True)\n",
    "df_test.cleaned_hm = df_test.cleaned_hm.apply(str.lower)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hmid</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88305</td>\n",
       "      <td>[1, 207, 6, 179, 9, 1877, 12, 2, 49]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88306</td>\n",
       "      <td>[21, 433, 105, 144, 51, 119, 44, 3, 5193, 21, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88307</td>\n",
       "      <td>[2, 702, 1766, 5, 10, 9, 579, 11, 2, 50, 9, 6,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88308</td>\n",
       "      <td>[1, 167, 4087, 20, 3, 1538, 246, 12, 41, 49]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88309</td>\n",
       "      <td>[1, 23, 29, 5, 3, 87, 246, 16, 3, 326, 12, 2, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hmid                                             tokens\n",
       "0  88305               [1, 207, 6, 179, 9, 1877, 12, 2, 49]\n",
       "1  88306  [21, 433, 105, 144, 51, 119, 44, 3, 5193, 21, ...\n",
       "2  88307  [2, 702, 1766, 5, 10, 9, 579, 11, 2, 50, 9, 6,...\n",
       "3  88308       [1, 167, 4087, 20, 3, 1538, 246, 12, 41, 49]\n",
       "4  88309  [1, 23, 29, 5, 3, 87, 246, 16, 3, 326, 12, 2, ..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_test_set = tokenizer.texts_to_sequences(df_test.cleaned_hm)\n",
    "df_test['tokens'] = encoded_test_set\n",
    "df_test.drop(['cleaned_hm'], axis=1, inplace=True)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hmid</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88305</td>\n",
       "      <td>[1, 207, 6, 179, 9, 1877, 12, 2, 49, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88306</td>\n",
       "      <td>[21, 433, 105, 144, 51, 119, 44, 3, 5193, 21, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88307</td>\n",
       "      <td>[2, 702, 1766, 5, 10, 9, 579, 11, 2, 50, 9, 6,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88308</td>\n",
       "      <td>[1, 167, 4087, 20, 3, 1538, 246, 12, 41, 49, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88309</td>\n",
       "      <td>[1, 23, 29, 5, 3, 87, 246, 16, 3, 326, 12, 2, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hmid                                             tokens\n",
       "0  88305  [1, 207, 6, 179, 9, 1877, 12, 2, 49, 0, 0, 0, ...\n",
       "1  88306  [21, 433, 105, 144, 51, 119, 44, 3, 5193, 21, ...\n",
       "2  88307  [2, 702, 1766, 5, 10, 9, 579, 11, 2, 50, 9, 6,...\n",
       "3  88308  [1, 167, 4087, 20, 3, 1538, 246, 12, 41, 49, 0...\n",
       "4  88309  [1, 23, 29, 5, 3, 87, 246, 16, 3, 326, 12, 2, ..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_test = pad_sequences(encoded_test_set, maxlen=max_len, padding='post')\n",
    "testset = [list(doc) for doc in padded_test]\n",
    "df_test['tokens'] = testset;\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40213, 100)\n"
     ]
    }
   ],
   "source": [
    "x_test = np.array([np.array(x) for x in df_test.tokens])\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40213, 7)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(x_test, batch_size=32, verbose=2)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohvs = []\n",
    "for pred in preds:\n",
    "    ohv = np.zeros((7), dtype='int8')\n",
    "    ohv[np.argmax(pred)] = 1\n",
    "    ohvs.append(ohv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [ohv_to_label[tuple(vec)] for vec in ohvs]\n",
    "df_test['predicted_category'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hmid</th>\n",
       "      <th>predicted_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88305</td>\n",
       "      <td>bonding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88306</td>\n",
       "      <td>affection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88307</td>\n",
       "      <td>affection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88308</td>\n",
       "      <td>bonding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88309</td>\n",
       "      <td>affection</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hmid predicted_category\n",
       "0  88305            bonding\n",
       "1  88306          affection\n",
       "2  88307          affection\n",
       "3  88308            bonding\n",
       "4  88309          affection"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.drop(['tokens'], axis=1, inplace=True)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv('D:/Datasets/mc-sent-2/sub_4.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
